{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "from math import hypot\n",
    "import math\n",
    "import winsound\n",
    "frequency=2500\n",
    "duration=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model=tf.keras.models.load_model(\"my_mask_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "facecascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facemask(frame):\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=facecascade.detectMultiScale(gray,1.1,4)\n",
    "    font=cv2.FONT_HERSHEY_PLAIN\n",
    "    m=0\n",
    "    for x,y,w,h in faces:\n",
    "        roi_gray=gray[y:y+h, x:x+w]\n",
    "        roi_color=frame[y:y+h, x:x+w]\n",
    "        facess=facecascade.detectMultiScale(roi_gray)\n",
    "        if len(facess)!=0:\n",
    "            for (ex,ey,ew,eh) in facess:\n",
    "                face_roi=roi_color[ey:ey+eh,ex:ex+ew]\n",
    "                final_image=cv2.resize(face_roi,(224,224))\n",
    "                final_image=np.expand_dims(final_image,axis=0)\n",
    "                Predictions=new_model.predict(final_image)\n",
    "                if (Predictions>0.5):\n",
    "                    status=\"No mask\"\n",
    "                    cv2.putText(frame,status,(x+6,y-6),font,1,(0,0,255),1)\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                    winsound.Beep(frequency,duration)\n",
    "                    m=m+1\n",
    "                else:\n",
    "                    status=\"Face mask\"\n",
    "                    cv2.putText(frame,status,(x+6,y-6),font,1,(0,255,0),1)\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)  \n",
    "        \n",
    "    text1 = \"Mask Violations: {}\".format(m)\n",
    "    cv2.putText(frame, text1, (10, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 2)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelsPath = \"./coco.names\"\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3),dtype=\"uint8\")\n",
    "weightsPath = \"./yolov3.weights\"\n",
    "configPath = \"./yolov3.cfg\"\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def person(image):  \n",
    "    (H, W) = image.shape[:2]\n",
    "    ln = net.getLayerNames()\n",
    "    ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "    blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > 0.8 and classID == 0:\n",
    "                box = detection[0:4]* np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "                \n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.1,0.064)\n",
    "    ind = []\n",
    "    for i in range(0,len(classIDs)):\n",
    "        if(classIDs[i]==0):\n",
    "            ind.append(i)\n",
    "            \n",
    "    a = []\n",
    "    b = []\n",
    "    color = (0,255,0)\n",
    "    if len(idxs) > 0:\n",
    "        for i in idxs.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            a.append(int((x+x+w)/2))\n",
    "            b.append(int((y+y+h)/2))\n",
    "            #cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "            \n",
    "    distance=[] \n",
    "    nsd = []\n",
    "    for i in range(0,len(a)-1):\n",
    "        for k in range(1,len(a)):\n",
    "            if(k==i):\n",
    "                break\n",
    "            else:\n",
    "                x_dist = (a[k] - a[i])\n",
    "                y_dist = (b[k] - b[i])\n",
    "                d = math.sqrt(x_dist * x_dist + y_dist * y_dist)\n",
    "                distance.append(d)\n",
    "                if(d<=300):\n",
    "                    nsd.append(i)\n",
    "                    nsd.append(k)\n",
    "                else:\n",
    "                    (x,y)=(boxes[i][0],boxes[i][1])\n",
    "                    (w,h)=(boxes[i][2],boxes[i][3])\n",
    "                    (x1,y1)=(boxes[k][0],boxes[k][1])\n",
    "                    (w1,h1)=(boxes[k][2],boxes[k][3])\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "                    cv2.rectangle(image,(x1,y1),(x1+w1,y1+h1),color,2)\n",
    "                nsd = list(dict.fromkeys(nsd))\n",
    "    color = (0, 0, 255)\n",
    "    \n",
    "    for i in nsd:\n",
    "        (x, y) = (boxes[i][0], boxes[i][1])\n",
    "        (w, h) = (boxes[i][2], boxes[i][3])\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "    text=\"Physical distance violation={}\".format(len(nsd))\n",
    "    cv2.putText(image, text, (10, 100), cv2.FONT_HERSHEY_SIMPLEX,0.85, color, 2)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "import tkinter\n",
    "from PIL import Image\n",
    "from PIL import ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#facemask and social distance\n",
    "class Root(Tk):\n",
    "    def __init__(self):\n",
    "        super(Root,self).__init__()\n",
    "        self.title(\"Social Distance and Facemask Detection\")\n",
    "        self.minsize(640,400)\n",
    "        self.labelFrame=ttk.LabelFrame(self,text=\"Detect in an image\")\n",
    "        self.labelFrame.grid(column=0,row=1,padx=20,pady=20)\n",
    "        self.button()\n",
    "        self.labelFrame1=ttk.LabelFrame(self,text=\"Detect in a video\")\n",
    "        self.labelFrame1.grid(column=1,row=1,padx=20,pady=20)\n",
    "        self.button1()\n",
    "        self.labelFrame2=ttk.LabelFrame(self,text=\"Detect in Webcam\")\n",
    "        self.labelFrame2.grid(column=2,row=1,padx=20,pady=20)\n",
    "        self.button2()\n",
    "        \n",
    "    def button(self):\n",
    "        self.button=ttk.Button(self.labelFrame,text=\"Browse an image\",command=self.fileDialog)\n",
    "        self.button.grid(column=1,row=1)\n",
    "        self.button=ttk.Button(self.labelFrame,text=\"Process\",command=self.imageprocess)\n",
    "        self.button.grid(column=2,row=1)\n",
    "    \n",
    "    def button1(self):\n",
    "        self.button1=ttk.Button(self.labelFrame1,text=\"Browse a video\",command=self.fileDialog1)\n",
    "        self.button1.grid(column=4,row=1)\n",
    "        self.button1=ttk.Button(self.labelFrame1,text=\"Process\",command=self.videoprocess)\n",
    "        self.button1.grid(column=5,row=1)\n",
    "        \n",
    "    def button2(self):\n",
    "        self.button2=ttk.Button(self.labelFrame2,text=\"Webcam\",command=self.webcam)\n",
    "        self.button2.grid(column=7,row=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fileDialog(self):\n",
    "        self.filename=filedialog.askopenfilename(initialdir='/',title=\"Select a file\",filetype=((\"jpeg files\",'*.jpg'),(\"png\",\"*.png\")))\n",
    "        self.label=ttk.Label(self.labelFrame,text=\"\")\n",
    "        self.label.grid(column=1,row=2)\n",
    "        self.label.configure(text=self.filename)\n",
    "        \n",
    "    def fileDialog1(self):\n",
    "        self.filename1=filedialog.askopenfilename(initialdir='/',title=\"Select a file\",filetype=((\"jpeg files\",'*.mp4'),(\"all\",\"*.*\")))\n",
    "        self.label1=ttk.Label(self.labelFrame1,text=\"\")\n",
    "        self.label1.grid(column=4,row=2)\n",
    "        self.label1.configure(text=self.filename1)\n",
    "        \n",
    "    def imageprocess(self):\n",
    "        self.img=cv2.imread(self.filename)\n",
    "        self.output=facemask(self.img)\n",
    "        self.output=person(self.output)\n",
    "        cv2.imshow('detection',self.output)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def videoprocess(self):\n",
    "        self.cap=cv2.VideoCapture(self.filename1)\n",
    "        while True:\n",
    "            _,self.frame=self.cap.read()\n",
    "            self.output=facemask(self.frame)\n",
    "            self.output=person(self.output)\n",
    "            cv2.imshow('detection',self.output)\n",
    "            if cv2.waitKey(1)==13:\n",
    "                break\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def webcam(self):\n",
    "        self.cap=cv2.VideoCapture(0)\n",
    "        while True:\n",
    "            _,self.frame=self.cap.read()\n",
    "            self.output=facemask(self.frame)\n",
    "            self.output=person(self.output)\n",
    "            cv2.imshow('webcam detection',self.output)\n",
    "            if cv2.waitKey(1)==13:\n",
    "                break\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__=='__main__':\n",
    "    root=Root()\n",
    "    root.mainloop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def facemask_dist(frame):\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces=facecascade.detectMultiScale(gray,1.1,4)\n",
    "    centroids=[]\n",
    "    MIN_DISTANCE=200\n",
    "    font=cv2.FONT_HERSHEY_PLAIN\n",
    "    violate=set()\n",
    "    m=0\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(frame,(x+1,y+1),(x+1+w,y+1+h),(255,0,0),1)\n",
    "        center_x=int((x+(x+w))/2)\n",
    "        center_y=int((y+(y+h))/2)\n",
    "        centroids.append((center_x,center_y))\n",
    "        roi_gray=gray[y:y+h, x:x+w]\n",
    "        roi_color=frame[y:y+h, x:x+w]\n",
    "        facess=facecascade.detectMultiScale(roi_gray)\n",
    "        if len(facess)!=0:\n",
    "            for (ex,ey,ew,eh) in facess:\n",
    "                face_roi=roi_color[ey:ey+eh,ex:ex+ew]\n",
    "                final_image=cv2.resize(face_roi,(224,224))\n",
    "                final_image=np.expand_dims(final_image,axis=0)\n",
    "                Predictions=new_model.predict(final_image)\n",
    "                if (Predictions>0.5):\n",
    "                    status=\"No mask\"\n",
    "                    cv2.putText(frame,status,(x+6,y-6),font,1,(0,0,255),1)\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "                    m=m+1\n",
    "                else:\n",
    "                    status=\"Face mask\"\n",
    "                    cv2.putText(frame,status,(x+6,y-6),font,1,(0,255,0),1)\n",
    "                    cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)  \n",
    "        if len(centroids)>=2:    \n",
    "            for i in range(len(centroids)-1):\n",
    "                for j in range(i+1,len(centroids)):\n",
    "                    D=hypot(centroids[i][0]-centroids[j][0],centroids[i][1]-centroids[j][1])\n",
    "                    if D<MIN_DISTANCE:\n",
    "                        violate.add(i)\n",
    "                        violate.add(j)\n",
    "                        cv2.circle(frame,centroids[i],5,(0,0,255),-1)\n",
    "                        cv2.putText(frame,'FDV',(centroids[i][0]+11,centroids[i][1]+11),font,1,(0,0,255),2)\n",
    "                        cv2.circle(frame,centroids[j],5,(0,0,255),-1)\n",
    "                        cv2.putText(frame,'FDV',(centroids[j][0]+11,centroids[j][1]+11),font,1,(0,0,255),2)\n",
    "                        cv2.line(frame,centroids[i],centroids[j],(0,0,255),1)\n",
    "         \n",
    "    text = \"Face Distancing Violations(FDV): {}\".format(len(violate))\n",
    "    cv2.putText(frame, text, (10, 25),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 2)\n",
    "    text1 = \"Mask Violations: {}\".format(m)\n",
    "    cv2.putText(frame, text1, (10, 60),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 2)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face distance\n",
    "class Root(Tk):\n",
    "    def __init__(self):\n",
    "        super(Root,self).__init__()\n",
    "        self.title(\"Social Distance and Facemask Detection\")\n",
    "        self.minsize(640,400)\n",
    "        self.labelFrame=ttk.LabelFrame(self,text=\"Detect in an image\")\n",
    "        self.labelFrame.grid(column=0,row=1,padx=20,pady=20)\n",
    "        self.button()\n",
    "        self.labelFrame1=ttk.LabelFrame(self,text=\"Detect in a video\")\n",
    "        self.labelFrame1.grid(column=1,row=1,padx=20,pady=20)\n",
    "        self.button1()\n",
    "        self.labelFrame2=ttk.LabelFrame(self,text=\"Detect in Webcam\")\n",
    "        self.labelFrame2.grid(column=2,row=1,padx=20,pady=20)\n",
    "        self.button2()\n",
    "        \n",
    "    def button(self):\n",
    "        self.button=ttk.Button(self.labelFrame,text=\"Browse an image\",command=self.fileDialog)\n",
    "        self.button.grid(column=1,row=1)\n",
    "        self.button=ttk.Button(self.labelFrame,text=\"Process\",command=self.imageprocess)\n",
    "        self.button.grid(column=2,row=1)\n",
    "    \n",
    "    def button1(self):\n",
    "        self.button1=ttk.Button(self.labelFrame1,text=\"Browse a video\",command=self.fileDialog1)\n",
    "        self.button1.grid(column=4,row=1)\n",
    "        self.button1=ttk.Button(self.labelFrame1,text=\"Process\",command=self.videoprocess)\n",
    "        self.button1.grid(column=5,row=1)\n",
    "        \n",
    "    def button2(self):\n",
    "        self.button2=ttk.Button(self.labelFrame2,text=\"Webcam\",command=self.webcam)\n",
    "        self.button2.grid(column=7,row=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def fileDialog(self):\n",
    "        self.filename=filedialog.askopenfilename(initialdir='/',title=\"Select a file\",filetype=((\"jpeg files\",'*.jpg'),(\"png\",\"*.png\")))\n",
    "        self.label=ttk.Label(self.labelFrame,text=\"\")\n",
    "        self.label.grid(column=1,row=2)\n",
    "        self.label.configure(text=self.filename)\n",
    "        \n",
    "    def fileDialog1(self):\n",
    "        self.filename1=filedialog.askopenfilename(initialdir='/',title=\"Select a file\",filetype=((\"jpeg files\",'*.mp4'),(\"all\",\"*.*\")))\n",
    "        self.label1=ttk.Label(self.labelFrame1,text=\"\")\n",
    "        self.label1.grid(column=4,row=2)\n",
    "        self.label1.configure(text=self.filename1)\n",
    "        \n",
    "    def imageprocess(self):\n",
    "        self.img=cv2.imread(self.filename)\n",
    "        self.output=facemask_dist(self.img)\n",
    "        cv2.imshow('detection',self.output)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def videoprocess(self):\n",
    "        self.cap=cv2.VideoCapture(self.filename1)\n",
    "        while True:\n",
    "            _,self.frame=self.cap.read()\n",
    "            self.output=facemask_dist(self.frame)\n",
    "            cv2.imshow('detection',self.output)\n",
    "            if cv2.waitKey(1)==13:\n",
    "                break\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "    def webcam(self):\n",
    "        self.cap=cv2.VideoCapture(0)\n",
    "        while True:\n",
    "            _,self.frame=self.cap.read()\n",
    "            self.output=facemask_dist(self.frame)\n",
    "            cv2.imshow('webcam detection',self.output)\n",
    "            if cv2.waitKey(1)==13:\n",
    "                break\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__=='__main__':\n",
    "    root=Root()\n",
    "    root.mainloop()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
